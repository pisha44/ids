{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ad5af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weight Matrix W1 (Input -> Hidden Layer 1):\n",
      " [[ 0.78920421  0.64426527  0.53269575  0.61298804 -0.00264436]\n",
      " [-1.18207288 -1.4302054   0.09495968  0.91961712  1.21020501]\n",
      " [ 1.7670974   1.87588059  0.08268574  0.70361356  0.23610271]\n",
      " [ 0.35403574  0.85994209  0.03569779  0.91519493  0.2057797 ]]\n",
      "\n",
      "Final Bias b1 (Hidden Layer 1):\n",
      " [[-0.36722904 -0.27791772  0.54433455  0.53543241  0.24174695]]\n",
      "\n",
      "Final Weight Matrix W2 (Hidden Layer 1 -> Hidden Layer 2):\n",
      " [[ 0.9988761   1.86783728  1.16407199]\n",
      " [ 0.88463499  2.22671423  1.39647357]\n",
      " [ 0.19033707 -0.14570102 -0.40704613]\n",
      " [ 0.46609532 -0.29391841 -0.37621352]\n",
      " [ 0.98322576 -0.75544444 -0.50131997]]\n",
      "\n",
      "Final Bias b2 (Hidden Layer 2):\n",
      " [[ 0.72580433 -1.08461383 -0.11202814]]\n",
      "\n",
      "Final Weight Matrix W3 (Hidden Layer 2 -> Output):\n",
      " [[-0.58932882]\n",
      " [ 3.15859511]\n",
      " [ 1.61912494]]\n",
      "\n",
      "Final Bias b3 (Output Layer):\n",
      " [[-1.17015659]]\n",
      "\n",
      "Total Number of Steps = 1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function: Sigmoid activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Function: Derivative of sigmoid (for backpropagation)\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Setting random seed (optional, for reproducibility)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ----- STEP 1: Initialize Parameters -----\n",
    "\n",
    "# Define input size (N) and hidden layer sizes\n",
    "N = 4           # Number of binary inputs\n",
    "hidden1_size = 5  # Number of neurons in Hidden Layer 1\n",
    "hidden2_size = 3  # Number of neurons in Hidden Layer 2\n",
    "output_size = 1   # Single binary output\n",
    "\n",
    "# Random input data (binary: 0 or 1)\n",
    "X = np.random.randint(0, 2, (10, N))  # 10 samples\n",
    "\n",
    "# Random target outputs (binary)\n",
    "y = np.random.randint(0, 2, (10, output_size))\n",
    "\n",
    "# Random initialization of weights and biases\n",
    "W1 = np.random.rand(N, hidden1_size)\n",
    "b1 = np.random.rand(1, hidden1_size)\n",
    "\n",
    "W2 = np.random.rand(hidden1_size, hidden2_size)\n",
    "b2 = np.random.rand(1, hidden2_size)\n",
    "\n",
    "W3 = np.random.rand(hidden2_size, output_size)\n",
    "b3 = np.random.rand(1, output_size)\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.1\n",
    "\n",
    "# ----- STEP 2: Training Loop -----\n",
    "steps = 1000  # Number of steps\n",
    "\n",
    "for step in range(steps):\n",
    "\n",
    "    # ---- Forward Propagation ----\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    z3 = np.dot(a2, W3) + b3\n",
    "    output = sigmoid(z3)\n",
    "\n",
    "    # ---- Compute Error ----\n",
    "    error = y - output\n",
    "\n",
    "    # ---- Backward Propagation ----\n",
    "    d_output = error * sigmoid_derivative(output)\n",
    "\n",
    "    d_hidden2 = d_output.dot(W3.T) * sigmoid_derivative(a2)\n",
    "\n",
    "    d_hidden1 = d_hidden2.dot(W2.T) * sigmoid_derivative(a1)\n",
    "\n",
    "    # ---- Update Weights and Biases ----\n",
    "    W3 += a2.T.dot(d_output) * lr\n",
    "    b3 += np.sum(d_output, axis=0, keepdims=True) * lr\n",
    "\n",
    "    W2 += a1.T.dot(d_hidden2) * lr\n",
    "    b2 += np.sum(d_hidden2, axis=0, keepdims=True) * lr\n",
    "\n",
    "    W1 += X.T.dot(d_hidden1) * lr\n",
    "    b1 += np.sum(d_hidden1, axis=0, keepdims=True) * lr\n",
    "\n",
    "# ----- STEP 3: Final Output -----\n",
    "\n",
    "print(\"Final Weight Matrix W1 (Input -> Hidden Layer 1):\\n\", W1)\n",
    "print(\"\\nFinal Bias b1 (Hidden Layer 1):\\n\", b1)\n",
    "\n",
    "print(\"\\nFinal Weight Matrix W2 (Hidden Layer 1 -> Hidden Layer 2):\\n\", W2)\n",
    "print(\"\\nFinal Bias b2 (Hidden Layer 2):\\n\", b2)\n",
    "\n",
    "print(\"\\nFinal Weight Matrix W3 (Hidden Layer 2 -> Output):\\n\", W3)\n",
    "print(\"\\nFinal Bias b3 (Output Layer):\\n\", b3)\n",
    "\n",
    "print(f\"\\nTotal Number of Steps = {steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39457e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
